{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T22:24:31.45638Z","iopub.execute_input":"2021-06-07T22:24:31.456818Z","iopub.status.idle":"2021-06-07T22:24:31.467452Z","shell.execute_reply.started":"2021-06-07T22:24:31.456782Z","shell.execute_reply":"2021-06-07T22:24:31.466195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_Titanic = pd.read_csv('../input/titanic-extended/full.csv')\ndf_Titanic.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:26:53.177504Z","iopub.execute_input":"2021-06-07T22:26:53.178035Z","iopub.status.idle":"2021-06-07T22:26:53.225592Z","shell.execute_reply.started":"2021-06-07T22:26:53.178001Z","shell.execute_reply":"2021-06-07T22:26:53.224884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.Sorunun Cevabi","metadata":{}},{"cell_type":"code","source":"df_titanic1= df_Titanic.copy()\ndf_titanic1.info()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:36:41.743996Z","iopub.execute_input":"2021-06-07T22:36:41.744471Z","iopub.status.idle":"2021-06-07T22:36:41.764045Z","shell.execute_reply.started":"2021-06-07T22:36:41.744405Z","shell.execute_reply":"2021-06-07T22:36:41.762825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  ********** 1- Create a multi-indexed dataframe ***************","metadata":{}},{"cell_type":"code","source":"index = [df_Titanic.Sex.unique(), df_Titanic.Embarked.unique()]\nindexes = pd.MultiIndex.from_product(index, names=[\"Sex\", \"Embarked\"])\n\ncolumn = [df_Titanic.Pclass.unique(), df_Titanic.Survived.unique()]\ncolumns = pd.MultiIndex.from_product(column, names=[\"Pclass\", \"Survived\"])\n\nprint(columns)\nprint(indexes)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:37:31.032095Z","iopub.execute_input":"2021-06-07T22:37:31.032769Z","iopub.status.idle":"2021-06-07T22:37:31.049162Z","shell.execute_reply.started":"2021-06-07T22:37:31.032712Z","shell.execute_reply":"2021-06-07T22:37:31.047887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_titanic2 = pd.DataFrame(np.random.randn(8,9), index=indexes, columns=columns)\ndf_titanic2","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:28:47.872651Z","iopub.execute_input":"2021-06-07T22:28:47.873118Z","iopub.status.idle":"2021-06-07T22:28:47.898979Z","shell.execute_reply.started":"2021-06-07T22:28:47.873082Z","shell.execute_reply":"2021-06-07T22:28:47.897619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ******************** 2- Create pivot table by using pivot *****************","metadata":{}},{"cell_type":"code","source":"df_titanic3= df_Titanic.iloc[:10].pivot(index='Name',columns='Ticket',values='Age')\ndf_titanic3","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:37:43.784785Z","iopub.execute_input":"2021-06-07T22:37:43.785194Z","iopub.status.idle":"2021-06-07T22:37:43.815756Z","shell.execute_reply.started":"2021-06-07T22:37:43.78516Z","shell.execute_reply":"2021-06-07T22:37:43.814536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ***** 3- Manipulate the table you obtained in the 1st task with the stack and unstack methods ","metadata":{}},{"cell_type":"code","source":"df_titanic4 = df_titanic2.stack([0,1]).unstack([0,3])\ndf_titanic4","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:29:39.295256Z","iopub.execute_input":"2021-06-07T22:29:39.295745Z","iopub.status.idle":"2021-06-07T22:29:39.32673Z","shell.execute_reply.started":"2021-06-07T22:29:39.295708Z","shell.execute_reply":"2021-06-07T22:29:39.325599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ******************** 4-  Create the table below using melt method *****************","metadata":{}},{"cell_type":"code","source":"df_titanic5 = df_Titanic.melt(id_vars=['Name','Embarked'], value_vars =['Sex', 'Age'], var_name='var1', value_name='var2').iloc[:10]\ndf_titanic5","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:37:58.668925Z","iopub.execute_input":"2021-06-07T22:37:58.66937Z","iopub.status.idle":"2021-06-07T22:37:58.694526Z","shell.execute_reply.started":"2021-06-07T22:37:58.669332Z","shell.execute_reply":"2021-06-07T22:37:58.693595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ********** 5- Create the following pivot tables using the pivot_table method **********","metadata":{}},{"cell_type":"code","source":"pd.pivot_table(df_Titanic, values=['Age','Fare'], index=\"Embarked\",aggfunc={'Age' : np.median,'Fare':np.mean})","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:38:07.32759Z","iopub.execute_input":"2021-06-07T22:38:07.328057Z","iopub.status.idle":"2021-06-07T22:38:07.350637Z","shell.execute_reply.started":"2021-06-07T22:38:07.328022Z","shell.execute_reply":"2021-06-07T22:38:07.349263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(df_Titanic, values=['Age','Fare'], index=['Embarked', 'Sex', 'Pclass'],aggfunc={'Age' : np.median,'Fare':np.mean})","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:38:14.89286Z","iopub.execute_input":"2021-06-07T22:38:14.89327Z","iopub.status.idle":"2021-06-07T22:38:14.925993Z","shell.execute_reply.started":"2021-06-07T22:38:14.893237Z","shell.execute_reply":"2021-06-07T22:38:14.924922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(df_Titanic, values=['Age','Fare'], index=['Embarked', 'Sex', 'Pclass'],aggfunc={'Age' : [np.median,np.std],'Fare':[np.mean,np.sum]})","metadata":{"execution":{"iopub.status.busy":"2021-06-07T22:38:20.283054Z","iopub.execute_input":"2021-06-07T22:38:20.283494Z","iopub.status.idle":"2021-06-07T22:38:20.327749Z","shell.execute_reply.started":"2021-06-07T22:38:20.283453Z","shell.execute_reply":"2021-06-07T22:38:20.326665Z"},"trusted":true},"execution_count":null,"outputs":[]}]}